{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b1680784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PENDING\n",
    "#use theta to calculate attack intention for first line has attack intention\n",
    "#adjust learning rate\n",
    "#MSE shud be minimized error value\n",
    "#hyberbolic tan for hidden layers\n",
    "\n",
    "#COMPLETED\n",
    "#Lower sample rate of data in matlab\n",
    "#change activation func of mid layers\n",
    "#have 2 hidden layers of 50 neurons each\n",
    "#calculate theta for 180 degrees\n",
    "#change header tab for pandas object for csv_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4fc5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Model\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import traceback\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7d45b",
   "metadata": {},
   "source": [
    "# G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa93a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate train and test files for g\n",
    "INPUT_DATA_DIR = \"../../mnt/c/Users/i_maa/Desktop/Thesis/Data_g/\" #should be \"../../mnt/c/Users/i_maa/Desktop/Thesis/Data/\"\n",
    "#INPUT_DATA_DIR = \"Desktop/Thesis/Data_g/\"\n",
    "TRAIN_DATA_COEFFICIENT = 0.8\n",
    "\n",
    "files = []\n",
    "\n",
    "\n",
    "#can use tf.io.gfile.glob + tf.data.experimental.make_csv_dataset instead\n",
    "for (dirpath, dirnames, filenames) in os.walk(INPUT_DATA_DIR):\n",
    "    files.extend(filenames)\n",
    "train_files_finish_g = int(len(files) * TRAIN_DATA_COEFFICIENT)\n",
    "train_files_g = files[0:train_files_finish_g]\n",
    "test_files_g = files[train_files_finish_g:len(files)]\n",
    "\n",
    "#print(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "249b395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator for fit func\n",
    "def generate_batches_g(files,batch_size):\n",
    "    counter = 0\n",
    "    while True:\n",
    "        fname = files[counter]\n",
    "        counter = (counter + 1) % len(files)\n",
    "        #frame = pd.read_csv(INPUT_DATA_DIR + fname)\n",
    "        frame= pd.read_csv(INPUT_DATA_DIR+fname,names=[\"Label\",\"Cell\",\"X\",\"Y\",\"Velocity\",\"Theta\",\"I1\",\"I2\",\"I3\"])\n",
    "        #print(frame.dtypes)\n",
    "        #print(frame)\n",
    "        #pre processing\n",
    "        \n",
    "        output_all = frame[[\"Label\"]]\n",
    "        output_all = tf.keras.utils.to_categorical(output_all,num_classes=7)\n",
    "        \n",
    "        input_all = frame[[\"X\",\"Y\",\"Velocity\",\"Theta\",\"I1\",\"I2\",\"I3\"]]\n",
    "        #print(input_all.dtypes)\n",
    "        for local_index in range(0,input_all.shape[0],batch_size):\n",
    "            input_local = input_all[local_index:(local_index+batch_size)]\n",
    "            output_local = output_all[local_index:(local_index+batch_size)]\n",
    "            \n",
    "            yield input_local,output_local\n",
    "            #print(input_local,output_local)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48f5dca8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " \n",
    "# train_generator_g = generate_batches_g(train_files_g,32)\n",
    "# print(next(train_generator_g))\n",
    "# print(next(train_generator_g))\n",
    "# print(next(train_generator_g))\n",
    "\n",
    "#loading data set from csv\n",
    "#files = {\"*.csv\"}\n",
    "#files = tf.io.gfile.glob(files)\n",
    "#dataset = tf.data.experimental.make_csv_dataset(files,1,column_names=[\"Index\",\"Cell\",\"X\",\"Y\",\"Z\",\"Theta\",\"I1\",\"I2\",\"I3\"],header=False,label_name=\"Index\"\n",
    "#print(dataset)\n",
    "\n",
    "#frame = pd.read_csv(INPUT_DATA_DIR + \"atrribute_vec1.csv\",names=[\"Index\",\"Cell\",\"X\",\"Y\",\"Z\",\"Theta\",\"I1\",\"I2\",\"I3\"])\n",
    "#test= frame[[\"Index\",\"Cell\"]]\n",
    "#print(test[1:4])\n",
    "#print(frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1ae735dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 50)                400       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,363\n",
      "Trainable params: 3,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 4s 22ms/step - loss: 1.5539 - accuracy: 0.5335 - val_loss: 1.0029 - val_accuracy: 0.6318\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 3s 16ms/step - loss: 0.8090 - accuracy: 0.7119 - val_loss: 0.6903 - val_accuracy: 0.7909\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.5996 - accuracy: 0.7830 - val_loss: 0.5584 - val_accuracy: 0.8205\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.5123 - accuracy: 0.8091 - val_loss: 0.4957 - val_accuracy: 0.8273\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.4651 - accuracy: 0.8222 - val_loss: 0.4692 - val_accuracy: 0.8409\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.4347 - accuracy: 0.8403 - val_loss: 0.4627 - val_accuracy: 0.8295\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.4133 - accuracy: 0.8477 - val_loss: 0.4478 - val_accuracy: 0.8341\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 3s 16ms/step - loss: 0.3975 - accuracy: 0.8523 - val_loss: 0.4298 - val_accuracy: 0.8364\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.3855 - accuracy: 0.8540 - val_loss: 0.4291 - val_accuracy: 0.8409\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 2s 15ms/step - loss: 0.3736 - accuracy: 0.8551 - val_loss: 0.4235 - val_accuracy: 0.8432\n",
      "INFO:tensorflow:Assets written to: G/assets\n"
     ]
    }
   ],
   "source": [
    "#init generator func\n",
    "batch_size=11\n",
    "train_generator_g = generate_batches_g(train_files_g,batch_size)\n",
    "\n",
    "#print(train_generator_g)\n",
    "test_generator_g = generate_batches_g(test_files_g,batch_size)\n",
    "# for x,y in iter(train_generator_g):\n",
    "#     print(y)\n",
    "# print(test_generator_g)\n",
    "#print(test_generator_g)\n",
    "#init model.fit\n",
    "callback_list = [EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(keras.Input(shape=(7,)))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu, input_shape=(7,)))\n",
    "model.add(tf.keras.layers.Dense(50, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(50, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(7, activation=tf.nn.softmax))\n",
    "#model.build(input_shape=(31,7,))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "train_dataset_g = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: generate_batches_g(files=train_files_g, batch_size=batch_size),\n",
    "    output_types=(tf.float32,tf.float32),\n",
    "    output_shapes=([None, 7], [None, 7])\n",
    ")\n",
    "\n",
    "test_dataset_g = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: generate_batches_g(files=test_files_g, batch_size=batch_size),\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, 7], [None, 7])\n",
    ")\n",
    "\n",
    "# try:\n",
    "hist2 = model.fit(\n",
    "    #x=generate_batches(train_files_g,batch_size),\n",
    "    x = train_dataset_g,\n",
    "    steps_per_epoch=len(train_files_g), \n",
    "    #validation_data=generate_batches(test_files_g,batch_size), \n",
    "    validation_data = test_dataset_g,\n",
    "    validation_steps=len(test_files_g), \n",
    "    epochs=10, \n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "# except Exception as e:\n",
    "#     raise e\n",
    "#     #print(traceback.format_exc())\n",
    "#     #traceback.print_exc()\n",
    "    \n",
    "#     # or\n",
    "    #print(sys.exc_info()[2])\n",
    "    \n",
    "\n",
    "model.save(\"G\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaccd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset_g)\n",
    "\n",
    "print('test acc:',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8ff9cbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 36 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f531869db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[0 0 4 0 5 3 4 0 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "#predicting_files = tf.io.gfile.glob(\"../../mnt/c/Users/i_maa/Desktop/Thesis/Data_g/atrribute_vec?.csv\")\n",
    "predicting_files = ['../../mnt/c/Users/i_maa/Desktop/Thesis/Data_g/atrribute_vec4.csv']\n",
    "#print(predicting_files)\n",
    "\n",
    "frame1= pd.read_csv(predicting_files[0],names=[\"Label\",\"X\",\"Y\",\"Velocity\",\"Theta\",\"I1\",\"I2\",\"I3\"])\n",
    "input1 = frame1[[\"X\",\"Y\",\"Velocity\",\"Theta\",\"I1\",\"I2\",\"I3\"]]\n",
    "input_l = input1[0:11]\n",
    "\n",
    "model = tf.keras.models.load_model('G')\n",
    "predict = model.predict(input_l)\n",
    "#predict = model.predict(generate_batches_g(predicting_files,batch_size))\n",
    "predict = np.argmax(predict, axis=1)\n",
    "print(predict)\n",
    "#print(input_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e7f25f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATADIR = \"../../mnt/c/Users/i_maa/Desktop/Thesis/Data/\"\n",
    "# train_set = os.path.join(DATADIR,'atrribute_vec1.csv')\n",
    "# test_set = os.path.join(DATADIR,'atrribute_vec2.csv')\n",
    "\n",
    "# df_train = pd.read_csv(train_set, names=[\"Index\",\"Cell\",\"X\",\"Y\",\"Z\",\"Theta\",\"I1\",\"I2\",\"I3\"])\n",
    "# df_test = pd.read_csv(test_set, names=[\"Index\",\"Cell\",\"X\",\"Y\",\"Z\",\"Theta\",\"I1\",\"I2\",\"I3\"])\n",
    "# #print(df_train) \n",
    "\n",
    "# df_train.head()\n",
    "\n",
    "# def get_features_labels(df):\n",
    "#     features = df[[\"X\",\"Y\",\"Z\",\"Theta\",\"I1\",\"I2\",\"I3\"]].values\n",
    "#     labels = df['Index'].values\n",
    "#     return features,labels\n",
    "\n",
    "\n",
    "# train_features,train_labels = get_features_labels(df_train)\n",
    "# test_features,test_labels = get_features_labels(df_test)\n",
    "# print(test_features.shape)\n",
    "# train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "# test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu, input_shape=(7,)))\n",
    "# model.add(tf.keras.layers.Dense(50, activation=tf.nn.relu))\n",
    "# model.add(tf.keras.layers.Dense(7, activation=tf.nn.softmax))\n",
    "\n",
    "# model.compile(loss = 'categorical_crossentropy',\n",
    "#               optimizer = 'rmsprop',\n",
    "#               metrics = ['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# EPOCHS =2\n",
    "# BATCH_SIZE=30\n",
    "\n",
    "# model.fit(train_features,train_labels, epochs =EPOCHS, batch_size = BATCH_SIZE)\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test_features,test_labels)\n",
    "\n",
    "# print('test acc:',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7edeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 14:31:17.942472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-31 14:31:17.942549: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a14861",
   "metadata": {},
   "source": [
    "# F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5a3b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atrribute_vec8.csv', 'atrribute_vec9.csv']\n"
     ]
    }
   ],
   "source": [
    "#seperate train and test files for g\n",
    "INPUT_DATA_DIR = \"../../mnt/c/Users/i_maa/Desktop/Thesis/Data_f/\" #should be \"../../mnt/c/Users/i_maa/Desktop/Thesis/Data/\"\n",
    "#INPUT_DATA_DIR = \"Desktop/Thesis/Data_g/\"\n",
    "TRAIN_DATA_COEFFICIENT = 0.8\n",
    "\n",
    "files = []\n",
    "\n",
    "\n",
    "#can use tf.io.gfile.glob + tf.data.experimental.make_csv_dataset instead\n",
    "for (dirpath, dirnames, filenames) in os.walk(INPUT_DATA_DIR):\n",
    "    files.extend(filenames)\n",
    "train_files_finish_f = int(len(files) * TRAIN_DATA_COEFFICIENT)\n",
    "train_files_f = files[0:train_files_finish_f]\n",
    "test_files_f = files[train_files_finish_f:len(files)]\n",
    "print(test_files_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57d1362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator for fit func\n",
    "def generate_batches_f(files,batch_size):\n",
    "    counter = 0\n",
    "    while True:\n",
    "        fname = files[counter]\n",
    "        counter = (counter + 1) % len(files)\n",
    "        frame= pd.read_csv(INPUT_DATA_DIR+fname,names=[\"X\",\"Y\",\"Velocity\",\"Theta\"])\n",
    "        #print(frame.dtypes)\n",
    "        \n",
    "        #pre processing\n",
    "    \n",
    "        output_all = pd.concat([frame[1:11],frame[10:11]])\n",
    "        #input_all = frame[[\"X\",\"Y\",\"Velocity\",\"Theta\"]]\n",
    "        input_all = frame\n",
    "        for local_index in range(0,input_all.shape[0],batch_size):\n",
    "            input_local = input_all[local_index:(local_index+batch_size)]\n",
    "            output_local = output_all[local_index:(local_index+batch_size)]\n",
    "            \n",
    "            yield input_local,output_local\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02249f03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 7)                 35        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 50)                400       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,189\n",
      "Trainable params: 3,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 31ms/step - loss: -949.0574 - accuracy: 0.5455 - val_loss: -634.5619 - val_accuracy: 0.7273\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -1377.5601 - accuracy: 0.6705 - val_loss: -764.1748 - val_accuracy: 0.7273\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -1634.8208 - accuracy: 0.6705 - val_loss: -904.6271 - val_accuracy: 0.7273\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: -1906.1989 - accuracy: 0.6705 - val_loss: -1052.1404 - val_accuracy: 0.7273\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: -2192.8201 - accuracy: 0.6705 - val_loss: -1213.5747 - val_accuracy: 0.7273\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -2517.5547 - accuracy: 0.6705 - val_loss: -1399.7849 - val_accuracy: 0.7273\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -2895.6187 - accuracy: 0.6705 - val_loss: -1610.3796 - val_accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -3312.5654 - accuracy: 0.6705 - val_loss: -1837.1616 - val_accuracy: 0.7273\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -3768.5049 - accuracy: 0.6705 - val_loss: -2083.9512 - val_accuracy: 0.7273\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: -4261.1562 - accuracy: 0.6705 - val_loss: -2350.7493 - val_accuracy: 0.7273\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -4798.8359 - accuracy: 0.6705 - val_loss: -2644.2622 - val_accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -5377.5522 - accuracy: 0.6705 - val_loss: -2957.5642 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: -6005.5464 - accuracy: 0.6705 - val_loss: -3300.9880 - val_accuracy: 0.7273\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -6681.7393 - accuracy: 0.6705 - val_loss: -3668.3557 - val_accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -7410.3105 - accuracy: 0.6705 - val_loss: -4064.5046 - val_accuracy: 0.7273\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -8190.7373 - accuracy: 0.6705 - val_loss: -4487.2700 - val_accuracy: 0.7273\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: -9027.9482 - accuracy: 0.6705 - val_loss: -4942.0571 - val_accuracy: 0.7273\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: -9923.0430 - accuracy: 0.6705 - val_loss: -5427.9917 - val_accuracy: 0.7273\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: -10876.0107 - accuracy: 0.6705 - val_loss: -5943.1777 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -11889.3135 - accuracy: 0.6705 - val_loss: -6491.0645 - val_accuracy: 0.7273\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -12973.2871 - accuracy: 0.6705 - val_loss: -7079.8472 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: -14130.9033 - accuracy: 0.6705 - val_loss: -7706.7217 - val_accuracy: 0.7273\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -15346.5869 - accuracy: 0.6705 - val_loss: -8362.4443 - val_accuracy: 0.7273\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -16645.4688 - accuracy: 0.6705 - val_loss: -9068.5693 - val_accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -18032.2031 - accuracy: 0.6705 - val_loss: -9819.9365 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -19494.6445 - accuracy: 0.6705 - val_loss: -10607.4932 - val_accuracy: 0.7273\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: -21035.9336 - accuracy: 0.6705 - val_loss: -11444.1094 - val_accuracy: 0.7273\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: -22669.1484 - accuracy: 0.6705 - val_loss: -12327.1396 - val_accuracy: 0.7273\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: -24377.7891 - accuracy: 0.6705 - val_loss: -13249.7959 - val_accuracy: 0.7273\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -26185.7129 - accuracy: 0.6705 - val_loss: -14231.3477 - val_accuracy: 0.7273\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: -28088.1680 - accuracy: 0.6705 - val_loss: -15264.1846 - val_accuracy: 0.7273\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -30086.8184 - accuracy: 0.6705 - val_loss: -16344.4414 - val_accuracy: 0.7273\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -32189.2500 - accuracy: 0.6705 - val_loss: -17486.1621 - val_accuracy: 0.7273\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -34395.8477 - accuracy: 0.6705 - val_loss: -18679.1113 - val_accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: -36711.0781 - accuracy: 0.6705 - val_loss: -19934.2285 - val_accuracy: 0.7273\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: -39136.1836 - accuracy: 0.6705 - val_loss: -21244.6289 - val_accuracy: 0.7273\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -41680.6133 - accuracy: 0.6705 - val_loss: -22623.8047 - val_accuracy: 0.7273\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: -44334.2500 - accuracy: 0.6705 - val_loss: -24057.9746 - val_accuracy: 0.7273\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -47123.9805 - accuracy: 0.6705 - val_loss: -25573.0000 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -50028.2227 - accuracy: 0.6705 - val_loss: -27140.2832 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -53069.2617 - accuracy: 0.6705 - val_loss: -28789.9062 - val_accuracy: 0.7273\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -56241.4023 - accuracy: 0.6705 - val_loss: -30505.6738 - val_accuracy: 0.7273\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -59561.4023 - accuracy: 0.6705 - val_loss: -32304.0430 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -63009.7734 - accuracy: 0.6705 - val_loss: -34167.0508 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -66607.0312 - accuracy: 0.6705 - val_loss: -36113.9336 - val_accuracy: 0.7273\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -70352.0469 - accuracy: 0.6705 - val_loss: -38140.2227 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -74260.8984 - accuracy: 0.6705 - val_loss: -40258.1836 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -78311.1953 - accuracy: 0.6705 - val_loss: -42443.7852 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -82546.6406 - accuracy: 0.6705 - val_loss: -44742.1367 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -86938.6328 - accuracy: 0.6705 - val_loss: -47114.2461 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -91507.6797 - accuracy: 0.6705 - val_loss: -49585.3789 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -96246.6953 - accuracy: 0.6705 - val_loss: -52147.8477 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -101173.9688 - accuracy: 0.6705 - val_loss: -54810.3281 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -106267.5234 - accuracy: 0.6705 - val_loss: -57561.1367 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -111573.9688 - accuracy: 0.6705 - val_loss: -60434.3125 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -117049.2031 - accuracy: 0.6705 - val_loss: -63387.9258 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -122729.0547 - accuracy: 0.6705 - val_loss: -66456.8203 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -128614.3203 - accuracy: 0.6705 - val_loss: -69640.4297 - val_accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -134728.5625 - accuracy: 0.6705 - val_loss: -72945.4297 - val_accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -141019.0156 - accuracy: 0.6705 - val_loss: -76336.8047 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -147544.1875 - accuracy: 0.6705 - val_loss: -79869.9297 - val_accuracy: 0.7273\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -154307.4375 - accuracy: 0.6705 - val_loss: -83525.4531 - val_accuracy: 0.7273\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: -161298.2812 - accuracy: 0.6705 - val_loss: -87298.1641 - val_accuracy: 0.7273\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: -168513.1406 - accuracy: 0.6705 - val_loss: -91193.6328 - val_accuracy: 0.7273\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -175984.6562 - accuracy: 0.6705 - val_loss: -95232.6484 - val_accuracy: 0.7273\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -183671.4375 - accuracy: 0.6705 - val_loss: -99373.9062 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -191634.6875 - accuracy: 0.6705 - val_loss: -103681.5781 - val_accuracy: 0.7273\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: -199839.0000 - accuracy: 0.6705 - val_loss: -108107.4922 - val_accuracy: 0.7273\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -208292.0938 - accuracy: 0.6705 - val_loss: -112667.7422 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: -217011.3594 - accuracy: 0.6705 - val_loss: -117378.0078 - val_accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -226033.4375 - accuracy: 0.6705 - val_loss: -122251.9531 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -235259.8594 - accuracy: 0.6705 - val_loss: -127212.0312 - val_accuracy: 0.7273\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -244811.5156 - accuracy: 0.6705 - val_loss: -132384.2344 - val_accuracy: 0.7273\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -254652.4531 - accuracy: 0.6705 - val_loss: -137690.0469 - val_accuracy: 0.7273\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -264762.3438 - accuracy: 0.6705 - val_loss: -143137.8594 - val_accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -275143.4688 - accuracy: 0.6705 - val_loss: -148735.5469 - val_accuracy: 0.7273\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -285871.0000 - accuracy: 0.6705 - val_loss: -154535.2812 - val_accuracy: 0.7273\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -296881.8125 - accuracy: 0.6705 - val_loss: -160467.3125 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -308196.6250 - accuracy: 0.6705 - val_loss: -166571.6406 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -319839.8750 - accuracy: 0.6705 - val_loss: -172854.8594 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -331792.2500 - accuracy: 0.6705 - val_loss: -179293.1406 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -344094.4375 - accuracy: 0.6705 - val_loss: -185939.9375 - val_accuracy: 0.7273\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -356766.1250 - accuracy: 0.6705 - val_loss: -192775.6875 - val_accuracy: 0.7273\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -369715.2812 - accuracy: 0.6705 - val_loss: -199743.0156 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -383039.5312 - accuracy: 0.6705 - val_loss: -206937.9062 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -396748.3125 - accuracy: 0.6705 - val_loss: -214334.4844 - val_accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -410792.4688 - accuracy: 0.6705 - val_loss: -221895.0156 - val_accuracy: 0.7273\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -425184.0938 - accuracy: 0.6705 - val_loss: -229651.9844 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -440006.0312 - accuracy: 0.6705 - val_loss: -237656.0625 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -455147.0000 - accuracy: 0.6705 - val_loss: -245799.5469 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -470727.4688 - accuracy: 0.6705 - val_loss: -254212.0000 - val_accuracy: 0.7273\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -486681.3125 - accuracy: 0.6705 - val_loss: -262804.1562 - val_accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -503014.7812 - accuracy: 0.6705 - val_loss: -271599.7188 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -519776.0312 - accuracy: 0.6705 - val_loss: -280642.4062 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -536994.5625 - accuracy: 0.6705 - val_loss: -289924.2812 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -554516.7500 - accuracy: 0.6705 - val_loss: -299340.3125 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -572534.0625 - accuracy: 0.6705 - val_loss: -309068.6250 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -591007.2500 - accuracy: 0.6705 - val_loss: -319022.7188 - val_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: -609884.1875 - accuracy: 0.6705 - val_loss: -329181.2188 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: -629162.3750 - accuracy: 0.6705 - val_loss: -339559.7188 - val_accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "#init generator func\n",
    "batch_size=11\n",
    "train_generator_f = generate_batches_f(train_files_f,batch_size)\n",
    "\n",
    "#print(train_generator_f)\n",
    "test_generator_f = generate_batches_f(test_files_f,batch_size)\n",
    "# for x,y in iter(train_generator_f):\n",
    "#     print(y)\n",
    "# print(test_generator_f)\n",
    "#print(test_generator_f)\n",
    "#init model.fit\n",
    "callback_list = [EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "#model.add(keras.Input(shape=(7,)))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(50, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(50, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(4, activation=tf.nn.softmax))\n",
    "#model.build(input_shape=(31,7,))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'rmsprop',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "train_dataset_f = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: generate_batches_f(files=train_files_f, batch_size=batch_size),\n",
    "    output_types=(tf.float64,tf.float64),\n",
    "    output_shapes=([None, 4], [None, 4])\n",
    ")\n",
    "\n",
    "test_dataset_f = tf.data.Dataset.from_generator(\n",
    "    generator=lambda: generate_batches_f(files=test_files_f, batch_size=batch_size),\n",
    "    output_types=(tf.float64, tf.float64),\n",
    "    output_shapes=([None, 4], [None, 4])\n",
    ")\n",
    "\n",
    "# try:\n",
    "hist2 = model.fit(\n",
    "    #x=generate_batches(train_files_f,batch_size),\n",
    "    x = train_dataset_f,\n",
    "    steps_per_epoch=len(train_files_f), \n",
    "    #validation_data=generate_batches(test_files_f,batch_size), \n",
    "    validation_data = test_dataset_f,\n",
    "    validation_steps=len(test_files_f), \n",
    "    epochs=100, \n",
    "    verbose=1 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81e05bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1292/Unknown - 13s 10ms/step - loss: -339561.6250 - accuracy: 0.7273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset_f)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest acc:\u001b[39m\u001b[38;5;124m'\u001b[39m,test_acc)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66m# In this case we have not created variables on the first call. So we can\u001b[39m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66m# run the first trace but we should fail if variables are created.\u001b[39m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66m# No tape is watching; skip to running the function.\u001b[39m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset_f)\n",
    "\n",
    "print('test acc:',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f97e4964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Updated\r\n"
     ]
    }
   ],
   "source": [
    "# frame= pd.read_csv(\"../../mnt/c/Users/i_maa/Desktop/Thesis/Data_f/atrribute_vec8.csv\",names=[\"X\",\"Y\",\"Velocity\",\"Theta\"])\n",
    "# #print(frame)\n",
    "# test_var = frame[0:11]\n",
    "# #print(frame.iloc(1))\n",
    "# #print(test_var)\n",
    "# #print(test_var.dtypes)\n",
    "# test_var = pd.concat([frame[1:11],frame[10:11]])\n",
    "# print(test_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cca392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
